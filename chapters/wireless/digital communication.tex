\chapter{Digital Communication}
This first section is all about how to convert and transmit some signal.
\begin{section}{Introduction}
\label{sec:intro}
The goal of communication is to transmit some kind of data form a sender to a receiver. In order 
to do so, the physical layer defines the means of transmitting a stream of \textbf{raw bits} over a
physical data link, which connects those two nodes.\\
Data is transmitted in the form of \textbf{signals}, which are a physical representation of the data.
The signal is transmitted over a \textbf{channel}, which is the transmission medium that connects 
the sender and receiver. This can be both wired or wireless.\\
% Whereas with wired channels, checking the device connected to the channel is easier to implement, 
% with wireless ones security is a major when travelling in the channel. This is for may reasons:
In wired channels, it is really easy to check which devices are connected to the channel, on the
other hand, in wireless channels the communication is broadcast, and security becomes a major
concern. This is for many reasons:
\begin{itemize}
  \item No inherent protection is applied to the channel( it is replaced by a logical association)
     \subitem sending and receiving messages do not need physical access to the network 
     infrastructure
  \item the communication is in broadcast, which is intrinsic of radio nature.
    \subitem Transmission can be overheard by anyone in range( which can be quite big, depending 
    on the situation), and anyone can generate a transmission, for example by jamming nearby 
    transmissions.
\end{itemize}
As a result:
\begin{itemize}
  \item Eavesdropping is easy
  \item Injecting fake messages into the communication in easy
  \item replaying previously recorded messages is easy(\textit{meaconing}). This is actually very 
    dangerous for gps positioning, so it is also a security concern.
  \item illegitimate access to the network and its services is easy
  \item Denial of service attacks are easy, achieved by jamming the channel.
\end{itemize}
% 9/43
\end{section}
\begin{section}{Digital Communication System}
The digital communication system in characterized by three sections: 

\begin{itemize}
  \item the \textbf{user section}, which consist in the transmitter and the receiver, that want to 
    communicate. 
  \item the \textbf{interface section}, which is the interface to conveying the signal from the 
    user to the analog channel. It also transforms bits to analog signal, compressing and encoding 
    them, also associating bits to signal waveforms, to transform bits to analog signal.
  \item the \textbf{channel section}, which is the physical medium, that can only propagate analog 
    waveforms. In the end, we want to transmit digital signal but we are forced to use analog ones.
\end{itemize}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{img/wireless/digital communication schema.png}
  \caption{Digital Communication System}
  \label{fig:Digital Communication System}
\end{figure}
\begin{subsection}{The transmitter chain}
The transmitter chain is the part of the system that takes the digital signal, or an analog one 
converted to digital, and converts it to an analog signal, that can be transmitted over the
channel.\\
It is basically composed by two parts. The first one being an \textbf{encoder}, which can limit the amount 
of bits transmitted(\textit{source encoding}), and/or make the transmitted sequence more robust to
errors(\textit{channel encoding}).\\
The second one is the \textbf{modulator}, which is the part of the system that takes the digital
signal and converts it to an analog one to transmit it over the channel.
\end{subsection}

\begin{subsection}{The channel}
  \label{subsec:channel}
The channel is the physical medium that transfers bits from interface to interface, from the sender
to the receiver.
Its operation is affected by different types of disturbances such as:
\begin{itemize}
	\item frequency-domain distortion
	\item wireless fading
	\item additive noise
	\item impulsive noise
	\item interference from other frequency channels (interchannel interference)
	\item interference from the same frequency channel (cochannel interference)
	\item Intentional interference
\end {itemize}
\end{subsection}
\begin{subsection}{The receiver chain}
The receiver chain is the part of the system that takes the analog signal from the channel and
converts it to a digital signal, that can be processed by the user.\\
It is composed by the dual counterpart of the transmitter chain, the \textbf{demodulator} and the
\textbf{decoder}. \\
The demodulator takes the analog signal and converts it to a sequence of samples that can be
processed by the decoder.\\
The decoder takes the sequence of samples and converts it to a digital signal. It implements
\textit{channel decoding}, to correct errors, and \textit{source decoding}, to recover the original
message.
\end{subsection}
\end{section}

\begin{section}{Signal representation and Processing}
  \begin{boxH}
    A \textbf{signal} is a (mathematical) function that conveys information about a phenomenon.
  \end{boxH}
  Basically, any quantity that varies over space or time can be used to represent a informations,
  allowing to describe the evolution of physical quantities over time(voltages, currents, \dots).\\
  Its mathematical representation is therefore a function of real variable (time) taking real or 
  complex(more than one) values.\\
  We will be mostly focused on Electromagnetic Signals (e.g. voltage), but the general concepts 
  can be applied to any kind of signal
  \begin{subsection}{Energy of a signal}
    The energy of a signal is the integral of the squared modulus of the signal itself.
    \begin{equation}
      E(x) = \int_{-\infty}^{\infty} |x(t)|^2 dt
    \end{equation}
    As we can see , the energy is a scalar value, and the whole function is made positive by the
    squared modulus.\\
    \begin{figure}[h]
      \centering
      \includegraphics[width=0.7\textwidth]{img/wireless/energy signal.png}
      \caption{Energy of a signal}
      \label{fig:Energy of a signal}
    \end{figure}
    A signal with a very large amplitude, over time, will have a very high energy, while a signal
    which assumes values close to zero will have a very low energy, being a very weak signal.\\
    Furthermore, we can notice that the higher the distance of the signal from the origin, the
    larger the energy.
  \end{subsection}
  \begin{subsection}{Power of a signal}
    When we refer to power we can refer to the \textbf{instantaneous power} of a signal, which is just the 
    square module of a signal
    \begin{equation}
      P(x) = |x(t)|^2
    \end{equation}
    but much more commonly we refer to the average power of a signal, which is the time average of
    the instantaneous power of the whole signal.
    \begin{equation}
      P(x) = \lim_{a \to \infty} \frac{1}{2a} \int_{-a}^{a} |x(t)|^2 dt
    \end{equation}
    This a again a scalar value.
  \end{subsection}
  \begin{subsection}{Signal Representation}
    To analyze and process the signals, it is necessary to adequately represent them, and the
    definition of signals as "time functions" is NOT effective for many applications, for many 
    reasons.\\
    Generally, signals can become very complicated depending on our communication system, and
    we want different ways of representing them, to make them easier to process.\\
    For instance, we can represent a signal as a sum of elementary signals, thanks to the scalar
    product of the signal with a basis of the space of signals.\\

    The scalar product between signals is a scalar value, which is a measure of the similarity 
    among signals.\\
    If two function are quite similar we will get a large number.
    It it is zero, they are said to be orthogonal.
    \begin{equation}
      \langle x,y \rangle = \langle x(t),y(t) \rangle = \int_{-\infty}^{\infty} x(t)y^*(t) dt
    \end{equation}

    So, if we have a set of elementary signals $w_1(t), w_2(t), \dots, w_m(t)$, we write the signal
    $x(t)$ as a linear combination of the elementary signals:
    \begin{equation}
      x(t) = \sum_{i=1}^{m} \alpha_i w_i(t)
    \end{equation}
    where $\alpha_i$ are the coefficients of the linear combination $\alpha_i = \langle x(t), 
    w_i(t) \rangle$.\\
    In a more down to hearth way, the coefficient $\alpha_i$ allows us to understand how much each
    individual signal is similar to any other elementary signal we are considering, and because the 
    scalar product is higher for similar signals, we can understand how much each elementary signal
    is contributing to the whole signal.\\

    Furthermore, by adjusting the coefficient, we are able to create a whole different signal using
    the same elementary signals.
    \begin{subsubsection}{A common example: In Phase and Quadrature components representation}
      \label{sub:IQ representation}
      Lets consider a very simple basis, or a set of elementary signals, which is actually more 
      important that many other ones:
      \begin{itemize}
        \item the \textbf{in-phase} signal, which, in this case, is a cosine function $w_1(t) = cos(2\pi f_o t)$
        \item the \textbf{quadrature} signal, which, in this case, is a sine function $w_2(t) = sin(2\pi f_o t)$
      \end{itemize}
      where $f_o$ is the frequency, in Hz, of the signal.\\
      We can write any signal as a linear combination of these two signals, just by adjusting the
      coefficients:
      \begin{equation}
        x(t) = x_1 cos(2\pi f_o t) + x_2 sin(2\pi f_o t)
      \end{equation}
      where x(t) is the signal we want to represent, and $x_1$ and $x_2$ are the coefficients of the
      linear combination.\\

      A very simple representation of this complex signal is obtainable by representing each signal 
      as an axes in a complex plane, for example in figure \ref{fig:Complex Plane} the x-axis 
      is the in-phase signal, and the y-axis is the quadrature signal.\\
      Each signal can be represented as a point in the complex plane, because the distance from the
      origin signal(\textit{axis}) is the amplitude of the signal.\\
      This kind of representation is called the \textbf{In-phase and Quadrature} representation, or
      \textbf{I/Q} representation.\\
      For example, choosing a point close to the x-axis, we are choosing a signal with a very low
      quadrature component, and a very high in-phase component.Furthermore, a set of those 
      different points is called a \textit{constellation}\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{img/wireless/iq representation.png}
        \caption{Some points that represent some signals in the I/Q representation}
        \label{fig:Complex Plane}
      \end{figure}
    \end{subsubsection}
  \end{subsection}
  \begin{subsection}{Fourier Analysis}
    Lets consider a signal with base the complex exponential functions 
    \begin{equation}
      e^{j2\pi \frac{n}{T} t} = cos(2\pi \frac{n}{T} t) + j sin(2\pi \frac{n}{T} t)
      \label{euler formula}
    \end{equation}
    It is actually characterized by a frequency $f_n = \frac{n}{T}$, where T is the period of the
    signal. The higher the frequency, the more oscillations we will have in the same time interval.
    In this function they have both the same frequency.\\

    We can use that function as a basis to decompose a signal, again. This is because it is 
    possible to generate an infinite set of functions
    \begin{equation}
      w_n(t) = \frac{1}{\sqrt{T}} e^{j\frac{2\pi}{T} nt} 
    \end{equation}
    with $-T/2 \leq t \leq T/2$, each associated with a frequency.
    That can be used ad a complete basis for all the signals limited in $[-T/2, T/2]$ or periodic.\\
    For example, we can write a signal as a linear combination of these functions:
    \begin{equation}
      x(t) = \frac{1}{\sqrt{T}} \sum_{n=-\infty}^{\infty} c_n e^{j\frac{2\pi}{T} nt}
      \label{Fourier Series}
    \end{equation}
    where $c_n$ are the coefficients of the linear combination $c_n = \langle x(t), w_n(t) \rangle$.\\
    Each one of those coefficients is a measure of how much each frequency $f_n$, of the $n$-th
    sinusoid(the shape of equation \ref{euler formula}) is present in the signal $x(t)$.\\
    \begin{figure}[h]
      \centering
      \includegraphics[width=0.7\textwidth]{img/wireless/euler plot.png}
      \caption{Plot of the coefficients of equation \ref{Fourier Series}}
      \label{fig:Fourier Analysis}
    \end{figure}
    Lets now take a look at picture \ref{fig:Fourier Analysis}. We can see that the coefficients
    are higher when the frequence is very small, so the signal \ref{Fourier Series} is mostly
    composed by large components of low frequency.\\
    This whole concept is called \textbf{Fourier Analysis}, or frequency analysis, which allows
    to decompose a signal into a set of frequencies.
    \begin{boxH}
    TLDR: I can build a signal trough a combination of frequency components. \\
    The coefficients of this frequency components are the measure of how much each frequency is 
    present in the signal.
    \end{boxH}
    Now we just need to expand it to any signal and any frequency( a continuous frequency domain).
    By doing so we can derive the definition of the \textbf{Fourier Transform} of a signal $x(t)$:
    \begin{equation}
      X(f) = \int_{-\infty}^{\infty} x(t) e^{-j2\pi ft} dt
      \label{Fourier Transform}
    \end{equation}
    where $X(f)$ is the Fourier Transform of the signal $x(t)$, and $f$ is the frequency.\\
    The Fourier transform is equivalent to a scalar product between the signal and the complex
    exponential function at a given frequency $f$. This means that each of the values of the
    Fourier Transform is a measure of how much the frequency $f$ is present in the signal $x(t)$.\\
    Furthermore, trough the inverse of equation \ref{Fourier Transform}
    \begin{equation}
      x(t) = \int_{-\infty}^{\infty} X(f) e^{j2\pi ft} df
      \label{Inverse Fourier Transform}
    \end{equation}
    we can write again a signal $x(t)$ as a linear combination of the complex exponential functions
    , which represents the frequency components of the signal, weighted by the Fourier Transform.\\
      
    \begin{boxH}
      The Fourier Transform $X(F)$ indicates the "weight" of each frequency component( sinusoidal
      component at a given frequency $f$) in the signal $x(t)$.\\
      The inverse Fourier Transform $x(t)$ tells us we can decompose any signal into frequency 
      components( sinusoidal components at a given frequency $f$).
    \end{boxH}
    
    \begin{figure}[h]
      \centering
      \includegraphics[width=0.9\textwidth]{img/wireless/fourier square function.png}
      \caption{Fourier Transform of a square function}
      \label{fig:Fourier Transform}
    \end{figure}

    With that in mind, take a look at figure \ref{fig:Fourier Transform}. It represents a rectangular
    signal (a signal that is 1 for a certain time, and 0 for the rest of the time), and its Fourier
    Transform, which tells us the frequency components of the signal.\\
    From that, we can see that the Fourier Transform is mostly composed by low frequency components,
    because values closer to zero are higher. That is because in the constant part of the signal
    has a sinusoidal component that constant.

    \begin{boxH}
      To wrap it up, for each signal we have a \textbf{spectral representation}. And for each operation
      over a signal, there are equivalents effects in the frequency domain.\\
      Furthermore, a signal that has finite duration in time, has a infinite support in the frequency
      domain.
    \end{boxH}
  \end{subsection}
  \begin{subsection}{Bandwidth}
    The bandwidth is the \textbf{interval of frequencies} that a signal occupies.\\
    If we consider a signal $x(t)$, we can define the bandwidth as the interval of frequencies
    where the Fourier Transform $X(f)$ is different from zero. \\ 
    Signals have often infinite support over the frequency domain over a finite duration, but many 
    of them are characterized by a quasi-null(finite) spectrum outside a certain interval of 
    frequencies( the main lobes of the spectrum).\\
    For this reason, we usually consider the bandwidth around half of the frequency spectrum of the
    signal, as shown in figure \ref{fig:Bandwidth}(for example 3dB bandwidth, or half power 
    bandwidth).\\
    \begin{figure}[h]
      \centering
      \includegraphics[width=0.8\textwidth]{img/wireless/bandwidth.png}
      \caption{Bandwidth of a signal}
      \label{fig:Bandwidth}
    \end{figure}
    \begin{subsubsection}{Bandwidth in linear systems}
      A \textbf{system} is a set of operations applied to signals.\\
      The relationship between the bandwidth of the input signal and the bandwidth of a system is
      usually very important. In fact, when a system is used to pass or remove particular 
      frequencies of a signal, it can be regarded as a system.\\
      We can associate a bandwidth to a system, specifically a \textbf{linear-time invariant} system,
      with a \textbf{frequency response} $H(f)$.This mean that we can associate a bandwidth to a
      system, making us able to compute a new bandwidth $Y(f)$ by combining together the bandwidth 
      $X(f)$ of the input signal and the frequency response $H(f)$ of the system($Y(f) = X(f)H(f)$
      in formulas).\\
      This concept can be represented graphically very easily, like in figure 
      \ref{fig:Bandwidth System}. If the result of the combination of the input signal and the
      sequence of operation of the system is a signal with a bandwidth $Y(f)$. If the bandwidth of 
      the linear system is larger than the origin signal, the signal pass trough smoothly($Y(f) \approx X(f)$).\\
      However, if the bandwidth of the signal is larger than the bandwidth of the system, the signal
      will be cutted off($Y(f) \ne H(f)$).\\

      \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{img/wireless/bandwidth system.png}
        \caption{Bandwidth of a system}
        \label{fig:Bandwidth System}
      \end{figure}
    \end{subsubsection}
  \end{subsection}

  \begin{subsection}{Filters}
    A filter is a system used to model desired and undesired effects over a signal.\\
    It is usually used to remove undesired frequency components from a signal, but overall can be
    used to:
    \begin{itemize}
      \item share the wireless medium
      \item model the spectrum of a signal over the channel
      \item mitigate undesired effects over a signal trough equalizers
    \end{itemize}
    \end{subsection}
    \begin{subsection}{Signal modulation}
      Signal modulation is the process of multiplying a signal by a sinusoidal function, resulting
      in a \textbf{frequency shift}.
      \begin{equation}
        y(t) = x(t) \cdot cos(2\pi f_0 t)
      \end{equation}
      This is possible because
      \begin{equation}
        F(x(t) \cdot cos(2\pi f_0 t)) = \frac{1}{2}[X(f-f_0) + X(f+f_0)]
      \end{equation}
      where $X$ is the frequency domain representation.\\ 
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{img/wireless/signal modulation.png}
        \caption{Graphical representation of the modulation}
        \label{fig:Modulation}
      \end{figure}
      We can see that as a result of the modulation, the spectrum of the signal is shifted around
      the frequency $f_0$, as shown in figure \ref{fig:Modulation}.\\

    \end{subsection}
    \begin{subsection}{Signal demodulation}
      When modulating a signal, we alter it a bit, centering it around the frequency $f_0$, shifting
      the spectrum of the signal. The effect of this operation is not trivial.\\
      To recover the original signal, we need to multiply the modulated signal by a sinusoidal
      function at the same frequency $f_0$ as the one used for the modulation. This allows us to
      shift the spectrum back to the original position.\\
      This operation is called \textbf{demodulation}.\\
      A given modulated signal $Y(f)$
      \begin{equation}
        Y(f) = \frac{A}{2}[X(f-f_0) + X(f+f_0)]
      \end{equation}
      shown in figure \ref{fig:Demodulation1}
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{img/wireless/demodulation1.png}
        \caption{A modulated signal at frequency $f_0$}
        \label{fig:Demodulation1}
      \end{figure}
      can be demodulated by multiplying it by the same sinusoidal function used for the modulation
      \begin{equation}
        Y'(f) = Y(f) \cdot cos(2\pi f_0 t)= \frac{A}{2}X(f)+\frac{A}{4}[X(f-2f_0)+X(f+2f_0)]
      \end{equation}
      shown in figure \ref{fig:Demodulation2}\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{img/wireless/demodulation2.png}
        \caption{A demodulated signal at frequency $f_0$}
        \label{fig:Demodulation2}
      \end{figure}
      This doesn't allow us to recover the original spectrum of the signal.
      That's why we need to use a \textbf{low-pass filter} to remove the frequency components at
      $2f_0$ and its symmetrical counterpart, as shown in figure \ref{fig:Demodulation3}.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{img/wireless/demodulation3.png}
        \caption{A demodulated signal at frequency $f_0$ after a low-pass filter}
        \label{fig:Demodulation3}
      \end{figure}

    \end{subsection}
    \begin{subsection}{Frequency Multiplexing(FDM)}
      \label{subsec:FDM}
      Modulation and demodulation allows multiple wireless communication systems to coexist at different
      frequencies.\\
      For example, if i want to transmit different signals with overlapping bandwidths, i can simply
      modulate each signal at a different frequency, and then transmit them all together, as shown in
      figure \ref{fig:FDM}.\\
      Once received the signal, each of those signals can be demodulated by multiplying it by the 
      same function at the same frequency used for the modulation.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.9\textwidth]{img/wireless/FDM.png}
        \caption{Frequency Multiplexing}
        \label{fig:FDM}
      \end{figure}
    \end{subsection}
    \begin{subsection}{Analog-to-Digital Conversion}
      We can now deal with signals, but we still have to convey information.\\
      The informations can be both \textbf{analog} or \textbf{digital}. Usually, transmitting digital
      information is ideal, because it has some advantages, such as error detection and correction,
      and the possibility to compress the information. On the other hand, we still have to convert
      digital information to analog information to be transmitted over the channel, after converting
      it to a stream of bits.\\
      Once the signal is received, it has to be converted back to digital information. To do so,
      first of all the signal it has to be sampled, which can be a lossless operation if the sampling
      frequency is high enough.\\
      After the sampling, the sample has to be quantized, which is the process of converting the
      amplitude of the sample to a digital value at discrete times( because it is a continuous
      time function, which would require an infinite number of digits to represent). Each of those 
      values is associated with a given amplitude, which is associated to a number, which 
      eventually is converted into binary digits. We can also observe that quantization is a lossy
      operation by definition.\\
      At the end of the fair, a sequence of bits is obtained, which can be transmitted over the
      channel.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=\textwidth]{img/wireless/analog to digital.png}
        \caption{Analog-to-Digital Conversion}
        \label{fig:ADC}
      \end{figure}
      \begin{subsubsection}{Sampling theorem}
        As previously stated, the sampling operation can be lossless if the sampling frequency is
        high enough. This is because of the \textbf{Nyquist sampling theorem}, which states
        that a signal can be perfectly reconstructed from its samples if the sampling frequency is
        at least twice the bandwidth of the signal.\\
        \begin{equation}
          f_c=\frac{1}{T_c}>2B\to T_c<\frac{1}{2B}
        \end{equation}
        where $f_c$ is the sampling frequency, $T_c$ is the sampling period, and $B$ is the bandwidth.
        \end{subsubsection}
    \end{subsection}
\end{section}

\begin{section}{Signal Transmission and Reception}
  Now that we know how a signal can be represented and processed, we can start to think how each 
  component of a communication system can be designed.\\
  \begin{subsection}{Digital Modulations}
    The end goal is to have a reliable communication system, which can transmit and receive
    information. As such, a important design choose is the signal waveform to transmit.\\
    The \textbf{modulator} is the component of the system that takes the digital information and 
    modulates it to a signal that can be transmitted over the channel. The demodulator component 
    just does the opposite, taking the signal and converting it back to digital information.\\

    \begin{boxH}
      \textbf{Modulation} is the process of varying one or more properties of a periodic waveform, called
      the \textbf{carrier}, with a modulating signal that typically contains information to be
      transmitted.
    \end{boxH}
    This process is necessary not only to cope with the analog channel, but also to allow multiple
    communication systems( which means different signals) to coexist in the same channel.\\

    Generally, digital and analog modulations resort to basic modulation types:
    \begin{itemize}
      \item \textbf{Amplitude Modulation(AM)}, which changes the amplitude of the carrier
      \item \textbf{Frequency Modulation(FM)}, which changes the frequency of the carrier
      \item \textbf{Phase Modulation(PM)}, which changes the phase of the carrier
    \end{itemize}

    This kind of modulation is necessary to convey information to the receiver, assigning to each
    possible value of the information signal a different amplitude, frequency or phase.
    \begin{subsubsection}{Amplitude Modulation(AM)}
      The amplitude modulation is the simplest form of modulation.\\
      The amplitude of an high-carrier signal(like a cosine signal) is varied according to the 
      instantaneous amplitude of the modulating message signal $m(t)$.\\
    \end{subsubsection}
    \begin{subsubsection}{Frequency Modulation(FM)}
      In frequency modulation, the frequency of the carrier signal is varied by the modulating
      signal $m(t)$, while the amplitude of the carrier signal is kept constant.\\
      This means that the as the amplitude of the information signal varies, the carrier frequency
      varies as well. For example, if the amplitude of the information signal increases, the
      frequency of the carrier signal increases as well.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{img/wireless/AM-FM.png}
        \caption{An example of a signal modulated in amplitude and frequency}
        \label{fig:AM-FM}
      \end{figure}
    \end{subsubsection}
    \begin{subsubsection}{Phase Modulation(PM)}
      Phase modulation is a form of modulation that encodes the signal $m(t)$ as a variation in the
      instantaneous phase of a carrier wave.\\
      This means that the phase of a carrier is modulated to follow the changing in the signal 
      amplitude of the message signal.\\

      The peak amplitude and the frequency of the carrier signal are maintained constant, but as 
      the amplitude of the message signal changes, the phase of the carrier changes 
      correspondingly.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{img/wireless/PM.png}
        \caption{An example of a signal modulated in phase. The modulating wave(in blue) is modulating
          the phase of the carrier wave(in red), resulting in the PM signal(in green)}
        \label{fig:PM}
      \end{figure}
    \end{subsubsection}
    \begin{subsubsection}{Analog-to-Digital modulations}
      Even if the world has turned to digital, transmitted signals are analog.\\
      This means that the digital information has to be converted to an analog signal to be
      transmitted over the channel. But the receiver still need to understand the digital information
      from the received signal.\\
      To be sure that the information can be recovered, the signal has to be modulated in a way that
      the receiver can understand the digital information. This can be done by varying some proprieties
      of the carrier signal, such as the amplitude, the frequency, or the phase, to represent the
      digital information.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{img/wireless/modulation encoding.png}
        \caption{Some example of modulations used to represent digital information. From top to bottom:
          Amplitude Shift Keying, Frequency Shift Keying, Phase Shift Keying}
        \label{fig:DigitalModulation}
      \end{figure}
      The carrier signal is used to modulate the digital information, so we can distinguish between
      different kinds of signals:
      \begin{itemize}
        \item the \textbf{the baseband signal}, which is the unmodulated signal, whose spectrum is
          centered around zero frequency
        \item the \textbf{passband signal}, which is the modulated signal, whose spectrum is centered
          around the carrier frequency
      \end{itemize}
      The baseband signal can be converted to a passband signal by multiplying it by a carrier signal
      with the desired frequency.\\
    \end{subsubsection}
    \begin{subsubsection}{Baseband Signals}
      The simplest kind of digital modulation is the \textbf{Pulse Amplitude Modulation(PAM)}, which
      is a form of modulation where the message signal is encoded in the amplitude of a series of
      signal pulses.\\
      For example, if we have a binary signal, we can encode the 0 as a low amplitude pulse $-A$, and the
      1 as a high amplitude pulse $A$. The simplest pulse is a rectangular one, but other kind of 
      pulses can be used.\\
      If we have a binary PAM(2-PAM), the signal can be represented as:
      \begin{itemize}
        \item $s(t)=g(t) \to "1"$
        \item $s(t)=-g(t) \to "0"$
      \end{itemize}
      where $g(t)$ is the basic pulse shape.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{img/wireless/2-PAM.png}
        \caption{An example of a 2-PAM signal representation}
        \label{fig:PAM}
      \end{figure}
    \end{subsubsection}
    \begin{subsubsection}{M-ary PAM}
      WA 2-PAM signal can only represent 1 bit of information. To represent more bits, we can use
      M-ary PAM, where M is the number of different symbols that can be represented, while still
      using the same base signal.\\
      For example, a 4-PAM signal can represent 2 bits of information by defining 4 levels of
      amplitude, and can be represented as:
      \begin{itemize}
        \item $s(t)=3g(t) \to "00"$
        \item $s(t)=g(t) \to "01"$
        \item $s(t)=-g(t) \to "10"$
        \item $s(t)=-3g(t) \to "11"$
      \end{itemize}
      This definition can be generalized to:
      \begin{equation}
        s_i(t)=A_i g(t),\quad i=1,2,\dots,M
      \end{equation}
      allowing to represent $log_2(M)$ bits of information.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{img/wireless/M-PAM.png}
        \caption{An example of a 4-PAM signal representation}
        \label{fig:4-PAM}
      \end{figure}
    \end{subsubsection}
    \begin{subsubsection}{Gray Coding}
      When using M-ary PAM, it is important to use a coding that minimizes the error probability.
      After all, Symbols that are close to each other in the signal space are more likely to be 
      confused, so the choice of the number of symbols and the distance between them is 
      important.\\
      \begin{boxH}
        \textbf{Gray coding} is a strategy to \textbf{mapping bits to symbols} that minimizes the
        probability of error.
      \end{boxH}
      Gray coding achieves 1-bit error correction, meaning that if a error is to occur, it will only
      affect 1 bit of the message with a high probability.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{img/wireless/gray coding.png}
        \caption{An example of a 4-PAM signal representation using Gray coding}
        \label{fig:GrayCode}
      \end{figure}
    \end{subsubsection}
    \begin{subsubsection}{Energy per bit}
      A measure of the energy efficiency of a modulation can be obtained by calculating the average
      energy per bit.\\
      The energy per bit can be defined as 
      \begin{equation}
        E_b=\frac{E_s}{log_2(M)}
      \end{equation}
      where $E_s$ is the energy of the signal, and $M$ is the number of symbols, or in a more
      discursive way, the average energy per symbol divided by the number of bits carried by 
      each symbol.\\
      This concept can also be visualized graphically, as the distance of a symbol from the origin
      in the signal space(as in figure \ref{fig:4-PAM}), because it is proportional to 
      energy of the symbol.\\

      The energy per symbol can be calculated as
      \begin{equation}
        E_s=\int_{0}^{T} (S_m(t))^2 dt= (A_m)^2 \int_{0}^{T} (g(t))^2 dt= (A_m)^2 E_g
      \end{equation}
      where $S_m(t)$ is the modulated signal, $A_m$ is the amplitude of the modulated signal, $g(t)$
      is the base pulse, and $E_g$ is the energy of the base pulse.\\

      For example, the average energy per symbol for the 4-PAM of figure \ref{fig:4-PAM} is
      \begin{equation}
        E_s=\frac{3^2T+1^2T+1^2T+3^2T}{4}=5T
      \end{equation}
      Generally, the larger the energy, the larger the distance between the symbols, and the lower
      the probability of error(mistaking one symbol for another). On the other hand, the larger the
      number of symbols over the same bandwidth, the less energy is required to transmit each bit(
      because each symbol is closer and carries more bits).\\
    \end{subsubsection}

    \begin{subsubsection}{Bandpass Signals}
      As previously stated, to transmit a baseband signal $s(t)$ trough a passband channel, we 
      have to modulate it at a certain frequency $f_c$, by multiplying it by a sinusoidal carrier
      signal with that frequency, otherwise it will be centered around zero frequency.\\
    \end{subsubsection}

    \begin{subsubsection}{Bandwidth Occupancy and efficiency}
      The shape of a signal determine the bandwidth it occupies.\\
      For example, a rectangular function has a pulse spectrum that is a sinc function, shown in
      figure \ref{fig:rectangular pulse spectrum}, which has a symbol rate of $1/T$(the amount of 
      symbols per second).

      \begin{figure}[h]
        \centering
        \includegraphics[width=0.6\textwidth]{img/wireless/rectangular pulse spectrum.png}
        \caption{The spectrum of a rectangular pulse}
        \label{fig:rectangular pulse spectrum}
      \end{figure}

      Usually, a smaller base pulse will require less energy to transmit, but will occupy more
      bandwidth. A longer basic pulse will require more energy to transmit, but will occupy less
      bandwidth and have a lower bit rate.\\

      With that in mind, ideally, we would like to choose a pulse shape $g(t)$ that minimizes the
      bandwidth occupancy, putting more energy in the lower frequencies, resulting in a smaller
      bandwidth.\\

      For a pulse duration $T$, we can define the \textbf{symbol rate} as $R_s=1/T$, and the
      \textbf{bit rate} as $R_b=R_s log_2(M)$(recall that $log_2(M)$ is the number of bits per
      symbol).\\
      The bit rate efficiency can be defined as
      \begin{equation}
        \eta=\frac{R_b}{BW}=\frac{log_2(M)}{T} \times (\frac{T}{2})=\frac{log_2(M)}{2}\text{bps/Hz}
      \end{equation}
      where $BW$ is the two sided bandwidth of the signal $BW=2R_2=\frac{2}{T}$.\\
      As we can see, the bit rate efficiency is proportional to the number of bits per symbol
      ($\eta \propto M$) and inversely proportional to the pulse duration. The duration of the 
      pulse is uninfluent.\\

      We can also consider some examples:
      \begin{itemize}
        \item 2-PAM: $\eta=\frac{1}{2}\text{bps/Hz}$
        \item 4-PAM: $\eta=\frac{2}{2}\text{bps/Hz}$
        \item 8-PAM: $\eta=\frac{3}{2}\text{bps/Hz}$
      \end{itemize}
      As we can see, the bandwidth efficiency increases with the number of bits per symbol, because
      we are fitting more bits in the same bandwidth.\\
      This also means that our signal will be more susceptible to noise, because the symbols are
      closer to each other, making it easier to mistake one for another. To reduce the probability
      of errors, we have to increase the energy per symbol, which will increase the bandwidth
      occupancy. For those reasons, there's a trade-off between bandwidth occupancy and energy
      efficiency.\\

      \begin{figure}[h]
        \centering
        \includegraphics[width=0.6\textwidth]{img/wireless/energy efficiency vs bandwidth occupancy.png}
        \caption{Trade-off between energy efficiency and bandwidth occupancy}
        \label{fig:energy efficiency vs bandwidth occupancy}
      \end{figure}

    \end{subsubsection}
    \begin{subsubsection}{Two-dimensional Modulation}
      As introduced in subsection \ref{sub:IQ representation}, signals can be represented over two 
      orthonormal basis. This means that we can represent a signal in a 2D plane, with the
      in-phase and quadrature components as the x and y axis.\\
      This representation allows to represent the set of signals $s_i$(also called \textit{constellation}
      over two orthonormal basis. A large constellation will allow to represent more bits per symbol,
      which results in a higher bit rate(bandwidth efficiency), but also a higher probability of 
      error.\\

      \begin{boxH}
        The shape of the constellation is important, because it can be used to minimize the probability
        of error, by choosing a constellation that minimizes the distance between the symbols.
      \end{boxH}
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{img/wireless/iq representation.png}
        \caption{A constellation of 4-PAM signals}
      \end{figure}
      Furthermore, there are some common constellations that are used in practice, such as:
      \begin{itemize}
        \item \textbf{QAM}: Quadrature Amplitude Modulation, which is a PAM signal over two
          dimensions.
        \item \textbf{PSK}: Phase Shift Keying, which is a PAM signal over the phase of a signal, 
          meaning that the amplitude is constant.
      \end{itemize}
    \end{subsubsection}

    \begin{subsubsection}{M-QAM}
      \begin{boxH}
        M-QAM is a modulation that represents the signal as the sum of two signals, represented over
        two orthonormal basis. This means that we can have $M$ symbols to modulate out signal.
      \end{boxH}
      Thus, we can represent $\sqrt{M}$ symbols over each axis, and the total number of
      symbols is $M$.\\
      This means that a symbol, represented over two orthonormal basis, can be described as 
      \begin{equation*}
        S_m=(A^x_m,A^y_m),A^x_m,A^y_m \in \{+/-1,\dots,+/-(\sqrt{M}-1)\}
      \end{equation*}
      for example:
      \begin{itemize}
        \item 4-QAM: $A^x_m,A^y_m \in \{+/-1\}$
        \item 16-QAM: $A^x_m,A^y_m \in \{+/-1,+/-3\}$
      \end{itemize}

      \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{img/wireless/16 QAM.png}
        \caption{A 16-QAM constellation}
      \end{figure}

      We recall that with QAM, the amplitude and phase of the signal are modulated. This means that
      by using the same pulse shape $g(t)$, the bandwidth efficiency is the same of a M-PAM, because
      the number of bits per symbol is the same, but with a larger energy efficiency, thanks to the
      presence of another dimension.\\

      By entering in the details, the in-phase and quadrature components of the signal are modulated
      by multiplying the components to orthogonal carriers, meaning that we can separate them 
      easily afterwards. This operation also transform the signal to a bandpass one.\\
      This is accomplished by multiplying the $A^x$ component by Cosine and the $A^y$ component by
      Sine, and then summing the two signals.\\

      The transmitted signal can thus be described as
      \begin{equation}
        U_m(t)= A_m^xg(t)cos(2\pi f_c t)+A_m^yg(t)sin(2\pi f_c t),m=1,\dots,M
      \end{equation}
      or in a more discursive way, each component of the signal is the amplitude value over one axis
      multiplied by the base pulse(the basis), and then multiplied by a carrier signal at a 
      given frequency.\\
    \end{subsubsection}
    \begin{subsubsection}{M-QAM modulation and demodulation}
      The general schema of M-QAM modulation is shown in figure \ref{fig:MQAM modulation}.\\
      We receive in input a series of bits, which are associated with the corresponding symbols, 
      one for each axis. The symbols used to modulate the pulse signal are then multiplied by the
      pulse shape, and then by the carrier signal. The two signals are then summed and transmitted.\\

      \begin{figure}[h]
        \centering
        \includegraphics[width=0.7\textwidth]{img/wireless/MQAM modulation.png}
        \caption{General schema of M-QAM modulation}
        \label{fig:MQAM modulation}
      \end{figure}

      As for what concerns the demodulation, we want to understand correctly the symbols that we
      receive, so we don't really care about the carrier signal. 
      We can notice that the sin and cosine components of the signal are orthogonal, meaning that
      we are able to separate them easily: the cosine component disappears after filtering when multiplied
      by the sine component, and viceversa.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{img/wireless/MQAM demodulation.png}
        \caption{General schema of M-QAM demodulation}
        \label{fig:MQAM demodulation}
      \end{figure}
    \end{subsubsection}
    \begin{subsubsection}{Phase Shift Keying}
      \begin{boxH}
        \textbf{Phase Shift Keying}(PSK) is a PAM signal over the phase of a signal.\\
        In a PSK constellation, the amplitude of the signal is constant, meaning that
        all the signals have the same energy.
      \end{boxH}

      This means that the symbols are equally spaced across a circle of radius $\sqrt{E_S}$, where
      $E_S$ is the energy of the signal.\\
      Symbols are thus equally spaced to minimize the probability of error.\\

      \begin{figure}[h]
        \centering
        \includegraphics[width=0.7\textwidth]{img/wireless/MPSK modulation.png}
        \caption{General schema of M-PSK modulation}
        \label{fig:MPSK modulation}
      \end{figure}
      The modulation process is similar to the one of M-QAM. We can notice that, because all the 
      amplitude values are so similar, resulting the waveforms have the same energy.
    \end{subsubsection}

    \begin{subsubsection}{Power amplifiers}
      After modulation, the signal is usually amplified by a \textbf{power amplifier} to increase
      the power of the signal.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{img/wireless/power amplifier.png}
        \caption{General schema of a power amplifier}
        \label{fig:power amplifier}
      \end{figure}
      Because we cannot have infinite energy, we can only amplify the signal to a certain level, 
      which is called \textbf{saturation level}.\\
      This has some effect on the constellations of a signals:
      \begin{itemize}
        \item when working with \textbf{PSK} signals, the constellation in amplified uniformly
          even when working in saturation.
        \item when working with \textbf{QAM} signals, the constellation is scaled differently, 
          making the probability of error higher.
      \end{itemize}

      \begin{figure}[h]
        \centering
        \subfloat[PSK constellation after amplification]{
          \includegraphics[width=0.4\textwidth]{img/wireless/PSK amplification.png}
          \label{fig:PSK amplification}
      }
        \hfill
        \subfloat[QAM constellation after amplification]{
          \includegraphics[width=0.4\textwidth]{img/wireless/QAM amplification.png}
          \label{fig:QAM amplification}
      }
        \caption{Effect of power amplification on a signal}
        \label{fig:constellation after amplification}
      \end{figure}
      When working under the saturation level, the power amplifier is linear, meaning that the
      output signal is proportional to the input signal, and no distortion occurs, but the 
      amplifier is underexploited.\\
      Thus, there is a trade-off between transmitted power and signal quality.\\
      
    \end{subsubsection}
  \end{subsection}

  \begin{subsection}{AWGN channel and equalization}
    Recall that to transmit information, we need to send a signal over a channel, in our case a 
    wireless one.\\
    We already briefly discussed the disturbance of a signals in subsection \ref{subsec:channel}, but the 
    main challenges can be summarized as:
    \begin{itemize}
      \item share the medium via \textbf{multiplexing}
      \item fight \textbf{noise} and \textbf{channel impairments}
    \end{itemize}
    The major sources of errors in the channel are essentualy two:
    \begin{itemize}
      \item \textbf{Termal noise}(AWGN), which is the result of the thermal agitation of the electrons
        in the receiver. It disturbs the signal in an additive fashion and occupies all the
        frequency band. Is also modelled by a Gaussian random process.
      \item \textbf{Inter-Symbol Interference}(ISI), which is the result of the signal being reflected
        by obstacles, and thus arriving at the receiver with a different phase and amplitude.
    \end{itemize}
    \begin{figure}[h]
      \centering
      \includegraphics[width=0.8\textwidth]{img/wireless/channel effect.png}
      \caption{Effects of the channel on a signal, $h(t)$ is a filter that models the channel with it impusle response,
        and $n(t)$ is the noise}
      \label{fig:channel effects}
    \end{figure}
    We can say that the channel ruin the signal. This is evident when looking at the spectrum of the
    signal, which is spread by the channel, shown in figure \ref{fig:channel effect on the spectrum}.\\
    \begin{figure}[h]
      \
      \centering
      \subfloat[Effect of the noise on the signal]{
        \includegraphics[width=0.4\textwidth]{img/wireless/signal AWGN effect.png}
        \label{fig:signal AWGN effect}
      }
      \hfill
      \subfloat[Signal spectrum distorted by inter-symbol interference, modelled by $h_c(t)$]{
        \includegraphics[width=0.4\textwidth]{img/wireless/signal filter effect.png}
        \label{fig:signal spectrum after channel}
      }
      \caption{Effect of the channel on the spectrum of a signal}
      \label{fig:channel effect on the spectrum}
    \end{figure}
    \begin{subsubsection}{Receiver Task}
      We want to design a receiver that can mitigate (or even revert) those two effects, to be 
      able to correctly understand the signal.\\
      To do so, we have to \textbf{demodulate} the signal and \textbf{equalize} it.\\
      This process can be carried out in 3 steps:
      \begin{enumerate}
        \item Improve the signal-to-noise ratio(SNR) using a \textbf{matched filter}
        \item Reduce Inter-Symbol Interference(ISI) using an \textbf{equalizer}
        \item Sample the recovered waveform and guess the transmitted symbol
      \end{enumerate}
      After those steps, we still have an imperfect signal wave, so we need to \textbf{detect} the
      transmitted symbol, thresholding the signals to remove outliers introduced in the channel 
      and decide with symbol was transmitted.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{img/wireless/receiver steps.png}
        \caption{General steps that a receiver has to carry out}
        \label{fig:receiver task}
      \end{figure}
    \end{subsubsection}

    \begin{subsubsection}{Maximize SNR}
      \begin{boxH}
        To maximize the signal-to-noise ratio, we can use a \textbf{matched filter} $h(t)=g(T-t)$
      \end{boxH}
      Turns out that the input response of the optimal filter is the time-reversed version of the
      pulse shape.\\
      The receiver must know the basic pulse shape to be able to use the matched filter.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.6\textwidth]{img/wireless/matched filter.png}
        \caption{Effect of the matched filter on the signal. They are kind of the same because
        the function is symmetrical}
        \label{fig:matched filter}
      \end{figure}
    \end{subsubsection}

    \begin{subsubsection}{Minimize ISI}
      Inter-Symbol Interference is the result  of the filtering effect of the channel, and can be
      defined as 
      \begin{equation}
        H_c(f)=|H_c(f)|e^{j\phi_c(f)}
      \end{equation}
      where $|H_c(f)|$ is the amplitude response of the channel, which is non-constant meaning 
      that it distorts the amplitude of the signal, and $\phi_c(f)$ is the phase response of the
      channel, which is non-linear, meaning that it distorts the phase of the signal.\\

      To revert those effects, we can use an \textbf{equalizer} to compensate for the distortion
      of the channel, which ideally would be the inverse of the channel($H_e(f)=\frac{1}{H_c(f)}$).\\
      Applying it to the signal allows us to get an approximation of the original symbol that was
      transmitted $\hat{S_i}(t)$.\\

      To build the equalizer we still need to know the frequency response of the channel.
      To do that, we can try to estimate the channel based on known characteristics of the signal.
      Usually we don't know them, so we introduce \textbf{pilot symbols} in the signal, which are
      known signals to the receiver, and can be used to estimate the channel.
    \end{subsubsection}

    \begin{subsubsection}{Fading}
      Depending on the channel, its impulse response can vary very slowly or very quickly.\\
      When the impulse response varies slowly, we talk about \textbf{slow fading}, and when it
      varies quickly, we talk about \textbf{fast fading}.\\
      Depending on this, pilots symbols may need to be transmitted more or less frequently.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.6\textwidth]{img/wireless/pilot transmission scheme.png}
        \caption{Pilot transmission scheme}
        \label{fig:pilot transmission}
      \end{figure}
    \end{subsubsection}
  \end{subsection}
  \begin{subsection}{Received symbols and decision regions}
    After equalizing the signal, we would like to decide which symbol was transmitted.\\
    As previously stated, we get a set of possible symbols $S_m\in\{S_1,S_2,...,S_M\}$, and we
    want to decide which one was transmitted, adopting a statistical approach.\\
    \begin{subsubsection}{Symbol Detection}
      Mathematically speaking, we have an hypothesis testing problem, which wants to minimize the
      probability of decision error, meaning that we want to choose the symbol that maximizes the
      probability of the received signal given the transmitted symbol.\\
      
      This is known as the \textbf{Maximum a posteriori probability} (MAP) decision rule, which
      simplify that rule. In fact, turns out that maximizing the probability of the received signal
      given the transmitted symbol is equivalent to minimizing the distance between the received
      signal and the transmitted symbol, under certain conditions.\\
      This is also known as \textbf{Minimum distance decoding} $d_{rS_m}=(r-S_m)^2$, where $r$ is the
      received signal(actual value of the signal plus the noise).\\

      Take for example the case of a 2-PAM signal, shown in figure \ref{fig:signal detection example}.
      The noise alter the received signal, so we can define it as $r=S_m+n$, where $n$ is the noise.
      We also know that the noise is a Gaussian random process, so we can suppose that the noise is
      more likely will be zero, and its less likely will be far from it.\\
      This means that it is possible to assume that the received signal $r$ is more likely to be the
      symbol $S_m$ that is actually closer to it.\\
      So, in this case, we can define the decision region as the interval $[-\infty,0)$ and $(0,\infty]$,
      and the decision rule as
      \begin{equation}
        \hat{S_m}=\begin{cases}
          S_1 & \text{if } r<0\\
          S_2 & \text{if } r\geq 0
        \end{cases}
      \end{equation}
      This can also be generalized to the case of M-PAM signals, because the general idea is still valid.
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{img/wireless/signal detection example.png}
        \caption{Example of signal detection}
        \label{fig:signal detection example}
      \end{figure}
    \end{subsubsection}
    \begin{subsubsection}{Probability of error}
      The Minimum Distance Decoding rule adopts a statistical approach to decide which symbol was
      transmitted, so it is possible to make errors.\\
      In general, the probability of error $P_e$ between two symbols separated by a distance $d$ is
      \begin{equation}
        P_e=Q\left(\frac{d}{2\sigma}\right)
      \end{equation}
      where $Q$ is a complex function, and $N_0$ is the noise density.\\
      The probability of error can be minimized by increasing the distance between the symbols.

      Based on that we can compute the probability of error per bit, or Bit Error Rate(BER), for 
      each modulation scheme.\\
      Under certain condition, for example grey coding, the BER can be approximated as
      \begin{equation}
        BER=\frac{P_e}{\log_2(M)}
      \end{equation}
      \begin{figure}[h]
        \centering
        \includegraphics[width=\textwidth]{img/wireless/BER plots.png}
        \caption{Examples of BER plots for different modulation schemes. The BER is higher at the same 
        SNR for denser modulation schemes}
        \label{fig:BER plots}
      \end{figure}
    \end{subsubsection}
  \end{subsection}
  \begin{subsection}{Signal Attenuation and Link Budget}
    During the propagation of a signal, especially in wireless medium, it suffers from an 
    attenuation $L$, which is the loss of power of the signal.\\
    In general, it depends on many environmental factors, such as the distance between the
    transmitter and the receiver, the frequency of the signal, the presence of obstacles, and so on.\\

    The relationship between transmission and reception power is given by the $P_{R}=P_{T}/L$, where
    $P_{R}$ is the received power, $P_{T}$ is the transmitted power, and $L$ is the attenuation.\\
    Given this relationship, we can define the Signal-to-Noise Ratio(SNR) perceived by the receiver
    as
    \begin{equation}
      SNR=\frac{E_b}{N_0}
    \end{equation}
    where $E_b$ the ratio between the Received Power and the Bit Rate, and $N_0$ is the noise density.\\
    In general, to deal with this problem, we use antennas and amplifiers to increase the power of the
    signal and compensate for the attenuation. The shape of the antenna allows to modulate the
    rate of the signal: for example a wider antenna allows to spread the signal in a isotropic way
    and reach a wider area, while a more focused antenna allows to reach a more specific one.\\
    This is measure by the \textbf{beamwidth} of the antenna $\theta_B$, which is a measure of the 
    directivity of the antenna.\\

    \begin{boxH}
      The smaller the beamwidth, the more focused the antenna is, hence we yield a higher gain, but
      we also have a smaller area of coverage.\\
      The larger the beamwidth, the more isotropic the antenna is, hence we yield a lower gain, but
      we also have a larger area of coverage.\\
    \end{boxH}
    For example, a parabolic antenna has a very small beamwidth, so $\theta_B \approx 70\gamma/D$
    where $D$ is the diameter of the antenna.\\
    In general, the gain $G_T$ is proportional to the area of the antenna, so $G_T\propto 1/D^2$.
    Doubling the diameter of the antenna, we get a 4 times increase in the gain.\\

    \begin{figure}[H]
      \centering
      \includegraphics[width=0.6\textwidth]{img/wireless/signal attenuation.png}
      \caption{Example of signal attenuation over a wireless medium}
      \label{fig:antenna gain}
    \end{figure}
  \end{subsection}
  \begin{subsection}{Multiple Access Schemes}
    \begin{boxH}
      As previously discussed in section \ref{subsec:FDM}, we to trasmitt multiple signals over the same
      same shared medium, we have to use a method called \textbf{multiplexing}.
    \end{boxH}
    Multiplexing allows to divide the available bandwidth over multiple logical channels.\\
    The multiplexed signals are then transmitted over the same medium, and then demultiplexed at the
    receiver.\\

    Multiplexing on itself is not enough to allow multiple users to transmit over the same medium.
    We also need to use a method called \textbf{Multiple Access}, which allows multiple users to
    transmit over the same medium.\\
    \begin{boxH}
      \textbf{Multiplexing} deals with \textbf{combining signals}, while \textbf{multiple access} 
      deals with allowing \textbf{multiple users} to access and share a communication medium.
    \end{boxH}
    \begin{subsubsection}{Frequency Division Multiplexing/Multiple Access}
      As previously discussed, FDM allows to divide the available bandwidth over multiple logical
      channels.\\
      In the case of multiple access, we can use FDM to divide the available bandwidth over multiple
      users, and then modulating each user's signal over a different carrier frequency.\\
      This is done by assigning a different frequency band to each user, so that they can transmit
      over the same medium without interfering with each other.\\
      This is the case of \textbf{Frequency Division Multiple Access} (FDM/FDMA).\\
      With this schema, each user get access to the full bandwidth for the whole time, being able to
      completely avoid interference, but if the user is not transmitting, the channel is wasted.\\
      Furthermore, it is necessary to have a guard band between the channels to avoid interference.\\
      \textit{ All wireless systems use this scheme}.
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{img/wireless/FDMA.png}
        \caption{Example of FDMA}
        \label{fig:FDMA}
      \end{figure}
    \end{subsubsection}
    \begin{subsubsection}{Time Division Multiplexing/Multiple Access}
      TDM is a method that allows to divide the available bandwidth over multiple logical channels,
      by assigning a different time slot to each user.\\
      This slot is allocated to the user even if it has no data to transmitt. For this method to 
      work correctly some kind of synchronization is needed, but each communication channel has
      access to the full bandwidth, even if it is only for a fraction of the time.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{img/wireless/TDMA.png}
        \caption{Example of TDMA}
        \label{fig:TDMA}
      \end{figure}
    In syncronous TDMA, many slots are wasted. There is a \textbf{statiscal version} of TDMA, called
    \textbf{STDM}, which reassigns the slots to the users that need them.\\
    This is done by scanning the input lines an collecting data until the frame is full, and then
    transmitting the frame.\\
    This method allows to avoid wasting slots, but it is more complex to implement, requiring 
    scheduling algorithms.\\
    \end{subsubsection}
    \begin{subsubsection}{Code Division Multiple Access}
      CDMA is a method that allows to divide the available bandwidth over multiple logical channels,
      by assigning a different code to each user.\\
      This method allows to exploit orthogonality between signals(allowing to separate them). Each
      channel has an unique code, while sharing the same spectrum(all of it) at the same time.\\
      Each channel is assigned a different code, and the receiver uses the unique binary code $c_i$
      of a sender to separate the signal from the others.\\

      For example a multiplexed signal
      \begin{equation*}
        s_{mux}(t)=s_1(t)c_1+s_2(t)c_2+s_3(t)c_3
      \end{equation*}
      is demultiplexed by the receiver using the code $c_1$ of the first sender
      \begin{equation*}
        \langle s_{mux}(t),c_1\rangle=s_1(t)
      \end{equation*}
      In this way, we are able to achieve a great bandwidth efficiency, with no need for coordination
      or synchronization while also getting a good degree of protection against interference.\\
      There are also some drawbacks: we have lower user data rates, and the system is more complex
      because the signals are more complex to regenerate.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{img/wireless/CDMA.png}
        \caption{Example of CDMA}
        \label{fig:CDMA}
      \end{figure}
    \end{subsubsection}
    \begin{subsubsection}{TDM/A + FDM/A}
      It is also possible to combine the two methods.
      We can combine the time and frequency division multiplexing, allowing to divide the available
      bandwidth over multiple logical channels, by assigning a different time slot and frequency band
      to each user.\\
      With this solution, we are able to achieve a better degree of protection against tapping
      and frequency selective interference, at the cost of higher data rates(compared to CDMA).\\
      This method also requires a precise coordination between the users.\\
      \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{img/wireless/TFDM.png}
        \caption{Example of TDMA/FDMA}
        \label{fig:TDMA/FDMA}
      \end{figure}
    \end{subsubsection}
  \end{subsection}

  \begin{section}{Source and channel coding}
    A brief overview: we have a source that generates a message, which is then encoded by the source
    encoder, to limit the amount of bits transmitted and the effects of noise.\\
    Those bits are then transformed into waveforms, which are altered by the channel, and then
    transformed back into bits by the channel decoder, after inverting the effects of the channel.\\

    Part of this operation are carried out in two steps:
    \begin{itemize}
      \item \textbf{Encoding}: which aims to produce a compressed representation $Y$ of the original
        message $X$. Usually encoding is simply a function $f$ that maps $X$ to $Y$.
      \item \textbf{Decoding}: which aims to recover the original message $X$ from the representation
        $Y$. Usually decoding is simply a function $f^{-1}$ that maps $Y$ to $X$.
    \end{itemize}
    \begin{figure}[h]
      \centering
      \includegraphics[width=0.2\textwidth]{img/wireless/encoding and decoding.png}
      \caption{General schema of encoding and decoding}
      \label{fig:encoding and decoding}
    \end{figure}

    \begin{subsection}{Source Coding}
      We would like to choose a encoding function $f$ that can be reverted while also \textbf{reducing
        redundancy} in the message.\\
        \begin{boxH}
          \textbf{Source coding}, also known as data compression, aims to represent information or
          data in a more compact form to reduce redundancy and save storage space or transmission 
          bandwidth.
        \end{boxH}
        This is possible because many real-world datasets exhibit patterns or repetitions that can 
        be efficiently encoded

        \begin{figure}[h]
          \centering
          \includegraphics[width=\textwidth]{img/wireless/source coding.png}
          \caption{Example of source coding}
          \label{fig:source coding}
        \end{figure}

        Figure \ref{fig:source coding} shows an example of source coding. The example supposes that
        a sequence of letters is being transmitted. A possible uncompressed representation of the 
        letters would be assigning a two bit code to each letter(fixed length code).\\
        An alternative strategy exploits the fact that some letters are more frequent than others,
        assigning shorter codes to the most frequent letters(variable length code). With this
        solution, we are able to reduce the number of bits needed to transmit the message.\\
        \begin{subsubsection}{Compression Types}
          There are two main compression classes:
          \begin{itemize}
            \item \textbf{Lossless Compression}: the original data can be perfectly reconstructed
              from the compressed data($\hat{X}=X$). This is useful when the original data must be 
              preserved exactly, such as in text or executable files. Some examples of lossless
              compression includes ZIP, RAR, and PNG.
            \item \textbf{Lossy Compression}: the original data cannot be perfectly reconstructed
              from the compressed data($\hat{X}\approx X$). This is useful when the original data 
              can be approximated or when some loss of quality is acceptable, such as in images 
              or audio files.
          \end{itemize}
          As there are no officials compression formats, the specifications are defined by the
          fidelity requirements of the application. Generally, there is a trade-off between the
          compression efficiency and the computational complexity of the algorithm.
        \end{subsubsection}
    \end{subsection}

    \begin{subsection}{Error Detection and Correction}
      After compression, all the redundancy of the message has been possibly removed, and the bits
      that make up the message are the ones to be transmitted.\\
      Ideally, the message should be received unaltered, but we know that the channel can introduce
      errors in the message.\\
      Error detection techniques allow detecting such errors, while error correction enables 
      reconstruction of the original data. But those schemes add some redundancy to the message.\\
      For doing this, there are two main approaches:
      \begin{itemize}
        \item \textbf{Automatic Repeat request(ARQ)}: it implements acknowledgements and timeouts
          to ensure that the message is correctly received. 
        \item \textbf{Forward Error Correction(FEC)/Channel coding}: it adds redundancy to the 
          message to allow
          the receiver to correct errors without the need for retransmission.
      \end{itemize}
      \begin{subsubsection}{Channel Coding}
        Channel coding aims to detect and correct errors that may occur during transmission.\\
        It adds redundant bits to the original message, creating a coded message that contains 
        extra information for error detection and correction.\\
        The effectiveness of a channel code is often measured by its error correction capability,
        indicating the maximum number of errors that can be corrected within a codeword.\\

        There are two main types of channel coding:
        \begin{itemize}
          \item \textbf{Block Codes}: the message is divided into blocks of fixed length, and a 
            fixed number of redundant bits are added to each block. The receiver uses the redundant
            bits to detect and correct errors.
          \item \textbf{Convolutional Codes}: the message is encoded using a convolutional encoder,
            which adds redundant bits based on the current and previous bits of the message. The 
            receiver uses a Viterbi decoder to detect and correct errors.
        \end{itemize}
      \end{subsubsection}
      \begin{subsubsection}{Block Codes}
        A block code acts on block of $k$ bits of input data to produce $n$ bits of output data.
        This operation is carried out by the channel encoder.\\
        It simply adds $n-k$ bits of redundancy to the original message, which can be used by the
        receiver to detect and correct errors.\\

        \begin{figure}[h]
          \centering
          \includegraphics[width=\textwidth]{img/wireless/block codes.png}
          \caption{Example of block code}
          \label{fig:block code}
        \end{figure}
      \end{subsubsection}
    \end{subsection}
  \end{section}
  \begin{section}{Questions and answers}
    \begin{subsubsection}{In a digital communication system, what is the role of source encoding and
      decoding? What is its main goal? Describe the working principle(s)}
      In a digital communication system, the communication is, as the name suggests, digital. The
      thing is, the channel is only able to carry analog signals, meaning that we need an interface
      to convert the digital signal into a an analog one, and vice versa. The user portion of the
      interface section of a digital communication schema, at first apply source encoding, reducing
      the number of bits to be stransmitted, and channel encoding, which makes the sequence more
      robust, all this in a modulator, and the data is at last converted to analog by an encoder.
      The receiver gets the analog signals and sample it with a decoder, from which a demodulator is
      able to retreive the digital data, even perfectly if the sample frequence is high enough, by
      doing channel and source decoding, which corrects errors and recovers the original message.
    \end{subsubsection}

    \begin{subsubsection}{Describe how different signals can coexist over the same wireless medium.}
      Different signals can coexist over the same shared medium thanks to a method called
      multiplexing, which allows to divide the available bandwidth over multiple logical channels.
      There are different multiplexing schemes:
      \begin{itemize}
        \item Frequency division multiplexing: thanks to the modulation and demodulation of signals,
          we can transmitt different signals with overlapping bandwidth, by modulating each signal
          at a different frequency. This schema require a guard band between channels to avoid
          interference, and it is basically used by all wireless systems, because each channel has
          access to the full bandwidth for the whole time.
        \item Time division multiplexing: the bandwidth is divided between the logical channels 
          by assigning a time slot to each user, even if no data has to be transmitted.
        \item Code division multiplexing allows to divide the available bandwidth over multiple
          logical channels, by assigning a different code to each user, which is used to separate
          the signal from the others, which share the same spectrum at the same time, by exploiting
          the orthogonality between signals.
      \end{itemize}
    \end{subsubsection}

    \begin{subsubsection}{Describe the tradeoff between bandwidth efficiency and energy efficiency
      in digital modulations.}
      We know that to achieve a higher bandwidth efficiency, one has to use a lower bandwidth. 
      Symbols are distributed over the bandwidth, and the larger the energy, the larger
      the bandwidth, and thus the distance between symbols. With a smaller bandwidth, those are
      cramped in a smaller "space". But using a smaller bandwidth means that we are using a larger
      base pulse, which occupies less bandwidth but require more energy. This means that if we
      choose to occupy a smaller bandwidth, the transmitted sequence is more prone to errors,
      because symbols are closer to each other, and require less energy to be transmitted. on the
      other hand, if we add more space inbetween symbols, we will occupy a larger bandwidth, which
      requires less energy to be transmitted and is less prine to errors.
    \end{subsubsection}

  \end{section}
\end{section}
